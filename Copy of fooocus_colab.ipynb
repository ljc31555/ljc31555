{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VjYy0F2gZIPR","outputId":"30501b80-3525-41b6-8842-4727e882577c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pygit2==1.12.2\n","  Downloading pygit2-1.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/4.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/4.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pygit2==1.12.2) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.9.1->pygit2==1.12.2) (2.22)\n","Installing collected packages: pygit2\n","Successfully installed pygit2-1.12.2\n","/content\n","Cloning into 'Fooocus'...\n","remote: Enumerating objects: 6389, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 6389 (delta 3), reused 8 (delta 0), pack-reused 6371\u001b[K\n","Receiving objects: 100% (6389/6389), 33.07 MiB | 11.48 MiB/s, done.\n","Resolving deltas: 100% (3654/3654), done.\n","/content/Fooocus\n","Already up-to-date\n","Update succeeded.\n","[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n","Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n","Fooocus version: 2.4.3\n","Error checking version for torchsde: No package metadata was found for torchsde\n","Installing requirements\n","[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n","[Cleanup] Cleanup successful\n","Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n","\n","100% 209k/209k [00:00<00:00, 118MB/s]\n","Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n","\n","100% 209k/209k [00:00<00:00, 24.1MB/s]\n","Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n","\n","100% 5.40M/5.40M [00:00<00:00, 326MB/s]\n","Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n","\n","100% 335M/335M [00:00<00:00, 372MB/s]\n","Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n","\n","100% 6.62G/6.62G [00:42<00:00, 167MB/s]\n","Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n","\n","100% 47.3M/47.3M [00:00<00:00, 346MB/s]\n","Total VRAM 15102 MB, total RAM 12979 MB\n","Set vram state to: HIGH_VRAM\n","Always offload VRAM\n","Device: cuda:0 Tesla T4 : native\n","VAE dtype: torch.float32\n","Using pytorch cross attention\n","2024-07-08 10:16:41.571243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-08 10:16:41.571300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-08 10:16:41.693074: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-07-08 10:16:44.088772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Refiner unloaded.\n","IMPORTANT: You are using gradio version 3.41.2, however version 4.29.0 is available, please upgrade.\n","--------\n","Running on local URL:  http://127.0.0.1:7865\n","model_type EPS\n","UNet ADM Dimension 2816\n","Running on public URL: https://6defff891fb6ec80f4.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","Using pytorch attention in VAE\n","Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n","Using pytorch attention in VAE\n","extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection'}\n","loaded straight to GPU\n","Requested to load SDXL\n","Loading 1 new model\n","Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n","VAE loaded: None\n","Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n","Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n","Fooocus V2 Expansion: Vocab with 642 words.\n","Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n","Requested to load SDXLClipModel\n","Requested to load GPT2LMHeadModel\n","Loading 2 new models\n","[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n","Started worker with PID 729\n","App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://6defff891fb6ec80f4.gradio.live\n","[Parameters] Adaptive CFG = 7\n","[Parameters] CLIP Skip = 2\n","[Parameters] Sharpness = 2\n","[Parameters] ControlNet Softness = 0.25\n","[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n","[Parameters] CFG = 4.0\n","[Parameters] Seed = 9105691728804642899\n","[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n","[Parameters] Steps = 30 - 15\n","[Fooocus] Initializing ...\n","[Fooocus] Loading models ...\n","Refiner unloaded.\n","[Fooocus] Processing prompts ...\n","[Fooocus] Preparing Fooocus text #1 ...\n","[Prompt Expansion] 大海, highly detailed, sharp focus, intricate, great composition, dynamic light, cinematic, elegant, colorful, artistic, fine detail, color, perfect background, vivid colors, aesthetic, very inspirational, professional, sublime, glowing, epic, best, winning, dramatic, beautiful, striking, attractive, shiny, futuristic, thought, luxury, awesome, stunning, cool\n","[Fooocus] Preparing Fooocus text #2 ...\n","[Prompt Expansion] 大海, awarded best novel, winning, detailed, attractive, cinematic, dramatic, draped background, aesthetic, sharp focus, clear professional, extremely detail, cute, glowing, perfect, emotional, elegant, epic, stunning, gorgeous, breathtaking, intricate, highly decorated, complex, wonderful, luxury, colorful, open great, amazing, marvelous, awesome, enormous, splendid\n","[Fooocus] Encoding positive #1 ...\n","[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n","[Fooocus] Encoding positive #2 ...\n","[Fooocus] Encoding negative #1 ...\n","[Fooocus] Encoding negative #2 ...\n","[Parameters] Denoising Strength = 1.0\n","[Parameters] Initial Latent shape: Image Space (896, 1152)\n","Preparation time: 5.60 seconds\n","[Fooocus] Preparing task 1/2 ...\n","[Sampler] refiner_swap_method = joint\n","[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n","Requested to load SDXL\n","Loading 1 new model\n","[Fooocus Model Management] Moving model(s) has taken 1.64 seconds\n","100% 30/30 [00:28<00:00,  1.07it/s]\n","Requested to load AutoencoderKL\n","Loading 1 new model\n","[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n","[Fooocus] Saving image 1/2 to system ...\n","Image generated with private log at: /content/Fooocus/outputs/2024-07-08/log.html\n","Generating and saving time: 33.12 seconds\n","[Fooocus] Preparing task 2/2 ...\n","[Sampler] refiner_swap_method = joint\n","[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n","Requested to load SDXL\n","Loading 1 new model\n","[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n","100% 30/30 [00:28<00:00,  1.04it/s]\n","Requested to load AutoencoderKL\n","Loading 1 new model\n","[Fooocus Model Management] Moving model(s) has taken 0.31 seconds\n","[Fooocus] Saving image 2/2 to system ...\n","Image generated with private log at: /content/Fooocus/outputs/2024-07-08/log.html\n","Generating and saving time: 32.72 seconds\n","Requested to load SDXLClipModel\n","Requested to load GPT2LMHeadModel\n","Loading 2 new models\n","Total time: 71.48 seconds\n","[Fooocus Model Management] Moving model(s) has taken 1.00 seconds\n"]}],"source":["!pip install pygit2==1.12.2\n","%cd /content\n","!git clone https://github.com/lllyasviel/Fooocus.git\n","%cd /content/Fooocus\n","!python entry_with_update.py --share --always-high-vram\n"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"Tjr9FcvG1wVh"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb","timestamp":1720432971575}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}